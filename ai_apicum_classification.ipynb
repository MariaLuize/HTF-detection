{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98f8668a-5587-403e-a635-e72471624589",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5c5295-bee8-4a3e-bb20-fef24d100c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, logging, ee, folium, glob, rasterio\n",
    "import json, datetime, math\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from rasterio.plot import show\n",
    "from osgeo import ogr, gdal\n",
    "\n",
    "logging.getLogger('googleapicliet.discovery_cache').setLevel(logging.ERROR)\n",
    "#GeForce RTX 2070\n",
    "gpu_dict = {'2070':{'GPU_AFFINTY':1,'GPU_MEMORY_LIMIT_GB':8}}\n",
    "sel_gpu = '2070'\n",
    "GPU_AFFINTY  = gpu_dict[sel_gpu]['GPU_AFFINTY'] \n",
    "GPU_MEMORY_LIMIT_GB =gpu_dict[sel_gpu]['GPU_MEMORY_LIMIT_GB']\n",
    "\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()\n",
    "\n",
    "EE_TILES = 'https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}'\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[GPU_AFFINTY], 'GPU')\n",
    "    GPU_MEMORY_LIMIT_GB = GPU_MEMORY_LIMIT_GB * 1e3\n",
    "    if GPU_MEMORY_LIMIT_GB == 0:\n",
    "        for gpu in gpus:\n",
    "          tf.config.experimental.set_memory_growth(gpu,True)\n",
    "    else:\n",
    "        tf.config.set_logical_device_configuration(gpus[GPU_AFFINTY],[tf.config.LogicalDeviceConfiguration(memory_limit=GPU_MEMORY_LIMIT_GB)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e: print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430cc871-ed02-4b3b-b64b-4e86ec87ed98",
   "metadata": {},
   "source": [
    "# ENV Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e4cfdd-5f64-48bc-b1d1-32950dc5ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_AFFINITY   = gpus[GPU_AFFINTY].name\n",
    "VERSION        = '2'\n",
    "MOSAIC_VERSION = '1'\n",
    "MAPBIOMAS_V    = '8'\n",
    "GOAL_CLASS     = 'apicum'\n",
    "BUCKET         = GOAL_CLASS+'_br'\n",
    "GDRIVE = 'mb'+MAPBIOMAS_V+'-unet-'+ GOAL_CLASS +'-brazil'\n",
    "\n",
    "GOAL_YEAR      = '2020'\n",
    "\n",
    "FOLDER_TRAIN   = 'training_samples'\n",
    "TRAINING_BASE  = 'training_patches_'+ MOSAIC_VERSION\n",
    "EVAL_BASE      = 'eval_patches_'+ MOSAIC_VERSION\n",
    "\n",
    "#Local paths\n",
    "LOCAL_PATH  = '/mnt/storage4/modelos/mb7-unet-'+GOAL_CLASS\n",
    "MODEL_DIR   = LOCAL_PATH+'/checkpoint/v'+VERSION\n",
    "OUTPUT_PATH = LOCAL_PATH+'/output/v'+VERSION\n",
    "\n",
    "# Exportation Configs\n",
    "BUCKET_patch = BUCKET\n",
    "FOLDER_patch = 'allPatch'\n",
    "FOLDER_classification = 'mb'+MAPBIOMAS_V+'_'+GOAL_CLASS+'_'+VERSION\n",
    "\n",
    "# Specify inputs (Landsat bands)\n",
    "opticalBands = ['swir1', 'nir', 'red','green','MNDWI','NDVI']\n",
    "BANDS        = opticalBands\n",
    "RESPONSE     = 'supervised'\n",
    "FEATURES     = BANDS + [RESPONSE]\n",
    "\n",
    "#Specify the size and shape of patches expected by the model.\n",
    "KERNEL_SIZE = 256\n",
    "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
    "COLUMNS = [\n",
    "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n",
    "]\n",
    "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
    "\n",
    "# Specify model training parameters.\n",
    "BATCH_SIZE  = 10\n",
    "DROPOUT     = 0.3\n",
    "BUFFER_SIZE = 1000\n",
    "OPTIMIZER   = 'Nadam' \n",
    "LOSS        = 'BinaryCrossentropy'\n",
    "METRICS     = ['RootMeanSquaredError']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3131fddd-9b1d-4d2f-a74f-285389291a7a",
   "metadata": {},
   "source": [
    "# Data Visualization (Supervised Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089a54b9-7e61-422a-ac0d-ce095a7b6240",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseClassV    = '2'\n",
    "yearClass_class  = '2020'\n",
    "yearClass_mosaic = '2020'\n",
    "version_final = '2'\n",
    "classID       = 32\n",
    "\n",
    "supervised_2020 = ee.Image('users/MariaLuizeSolvedCurso/Masters/supervisedImage_unet_mb7_'+GOAL_CLASS+'_'+yearClass_class+'_v' +baseClassV).eq(classID).rename(RESPONSE);\n",
    "supervisedChannel= supervised_2020.toByte().rename(RESPONSE);\n",
    "\n",
    "image = ee.Image('users/MariaLuizeSolvedCurso/Masters/mosaic_'+yearClass_mosaic).addBands(supervisedChannel)\n",
    "mapid=image.getMapId({'bands':['swir1','nir','red'],'min':30,'max':150})\n",
    "map = folium.Map(location=[-23.0089, -43.6078],zoom_start=13)\n",
    "folium.TileLayer(\n",
    "    tiles=mapid['tile_fetcher'].url_format,\n",
    "    attr='Planet', overlay=True,name='Mosaic composite',\n",
    "  ).add_to(map)\n",
    "  \n",
    "mapid=supervisedChannel.select(RESPONSE).getMapId({'min':0,'max':1})\n",
    "folium.TileLayer(\n",
    "    tiles=mapid['tile_fetcher'].url_format,\n",
    "    attr='Google Earth Engine',\n",
    "    overlay=True,\n",
    "    name='Apicum '+yearClass_class,\n",
    "  ).add_to(map)\n",
    "map.add_child(folium.LayerControl())\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bc01c6-b9d6-4265-8baa-2a7654c98d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureStack = ee.Image.cat([\n",
    "  image.select(BANDS).unmask(0),\n",
    "  image.select(RESPONSE).unmask(0)\n",
    "]).float()\n",
    "\n",
    "list = ee.List.repeat(1, KERNEL_SIZE)\n",
    "lists = ee.List.repeat(list, KERNEL_SIZE)\n",
    "kernel = ee.Kernel.fixed(KERNEL_SIZE, KERNEL_SIZE, lists)\n",
    "arrays = featureStack.neighborhoodToArray(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5cebbc-364a-4dff-b9f9-51e0319548b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearClass_geoms = '2020'\n",
    "trainingPolys_v1 = ee.FeatureCollection('users/MariaLuizeSolvedCurso/Masters/Geoms/trainPolys_apicum_'+yearClass_geoms+'_v1')\n",
    "evalPolys_v1     = ee.FeatureCollection('users/MariaLuizeSolvedCurso/Masters/Geoms/testPolys_apicum_'+yearClass_geoms+'_v1')\n",
    "\n",
    "trainingPolys_v2 = ee.FeatureCollection('users/MariaLuizeSolvedCurso/Masters/Geoms/trainPolys_apicum_'+yearClass_geoms+'_v2_update')\n",
    "evalPolys_v2     = ee.FeatureCollection('users/MariaLuizeSolvedCurso/Masters/Geoms/testPolys_apicum_'+yearClass_geoms+'_v2_update')\n",
    "\n",
    "trainingPolys = trainingPolys_v1.merge(trainingPolys_v2)\n",
    "evalPolys     = evalPolys_v1.merge(evalPolys_v2)\n",
    "polyImage = ee.Image(0).byte().paint(trainingPolys, 1).paint(evalPolys, 2)\n",
    "polyImage = polyImage.updateMask(polyImage)\n",
    "\n",
    "mapid = polyImage.getMapId({'min': 1, 'max': 2, 'palette': ['red', 'blue']})\n",
    "map = folium.Map(location=[-1.3621, -45.2738], zoom_start=5)\n",
    "folium.TileLayer(\n",
    "    tiles=mapid['tile_fetcher'].url_format,\n",
    "    attr='Google Earth Engine',\n",
    "    overlay=True,\n",
    "    name='training polygons',\n",
    "  ).add_to(map)\n",
    "map.add_child(folium.LayerControl())\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfc973c-c0b6-4b17-8791-20ecb067bb48",
   "metadata": {},
   "source": [
    "# Train/Test Chips Exportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58812f11-9a90-4378-9e7d-a91fdc806619",
   "metadata": {},
   "outputs": [],
   "source": [
    "version_samples_acc = \"2\"\n",
    "# Convert the feature collections to lists for iteration.\n",
    "trainingPolysList =trainingPolys.toList(trainingPolys.size())\n",
    "evalPolysList = evalPolys.toList(evalPolys.size())\n",
    "# These numbers determined experimentally.\n",
    "n = 20 # Number of shards in each polygon.\n",
    "N = 200 # Total sample size in each polygon.\n",
    "FOLDER_TEST    = 'testing_samples'\n",
    "\n",
    "#Add some generalism\n",
    "TRAIN_SIZE = trainingPolys.size().getInfo()*N\n",
    "EVAL_SIZE = evalPolys.size().getInfo()*N\n",
    "print('TRAIN:'+str(TRAIN_SIZE))\n",
    "print('EVAL:'+str(EVAL_SIZE))\n",
    "GDRIVE = 'MB8_Apicum'\n",
    "# Export all the training data (in many pieces), with one task per geometry.\n",
    "for g in range(trainingPolys.size().getInfo()):\n",
    "  geomSample = ee.FeatureCollection([])\n",
    "  for i in range(n):\n",
    "    sample = arrays.sample(\n",
    "      region = ee.Feature(trainingPolysList.get(g)).geometry(), \n",
    "      scale = 30, \n",
    "      numPixels = N / n, # Size of the shard.\n",
    "      seed = i,\n",
    "      tileScale = 8\n",
    "    )\n",
    "    geomSample = geomSample.merge(sample)\n",
    "  \n",
    "  desc = TRAINING_BASE + '_g' + str(g)\n",
    "  task = ee.batch.Export.table.toDrive(\n",
    "    collection = geomSample,\n",
    "    description = desc, \n",
    "    folder = GDRIVE+'/'+FOLDER_TRAIN+'_v'+version_samples_acc, \n",
    "    fileNamePrefix = desc,\n",
    "    fileFormat = 'TFRecord',\n",
    "    selectors = BANDS + [RESPONSE]\n",
    "  )\n",
    "  task.start()\n",
    "\n",
    "# Export all the evaluation data.\n",
    "for g in range(evalPolys.size().getInfo()):\n",
    "  geomSample = ee.FeatureCollection([])\n",
    "  for i in range(n):\n",
    "    sample = arrays.sample(\n",
    "      region = ee.Feature(evalPolysList.get(g)).geometry(), \n",
    "      scale = 30, \n",
    "      numPixels = N / n,\n",
    "      seed = i,\n",
    "      tileScale = 8\n",
    "    )\n",
    "    geomSample = geomSample.merge(sample)\n",
    "  \n",
    "  desc = EVAL_BASE + '_g' + str(g)\n",
    "  task = ee.batch.Export.table.toDrive(\n",
    "    collection = geomSample,\n",
    "    description = desc, \n",
    "    folder = GDRIVE+'/'+FOLDER_TEST+version_samples_acc, \n",
    "    fileNamePrefix = desc,\n",
    "    fileFormat = 'TFRecord',\n",
    "    selectors = BANDS + [RESPONSE],\n",
    "  )\n",
    "  task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaf8aff-dd1c-4926-9e60-53ddda04ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainingPolys.size().getInfo())\n",
    "print(evalPolys.size().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cc5c92-304a-44f0-8048-cf6ff96704f1",
   "metadata": {},
   "source": [
    "# Datasets Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4263875-04d6-423b-a33b-aef96008ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord(example_proto):\n",
    "  \"\"\"The parsing function.\n",
    "  Read a serialized example into the structure defined by FEATURES_DICT.\n",
    "  Args:\n",
    "    example_proto: a serialized Example.\n",
    "  Returns: \n",
    "    A dictionary of tensors, keyed by feature name.\n",
    "  \"\"\"\n",
    "  print(FEATURES_DICT)\n",
    "  return tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
    "\n",
    "\n",
    "\n",
    "def to_tuple(inputs):\n",
    "  \"\"\"Function to convert a dictionary of tensors to a tuple of (inputs, outputs).\n",
    "  Turn the tensors returned by parse_tfrecord into a stack in HWC shape.\n",
    "  Args:\n",
    "    inputs: A dictionary of tensors, keyed by feature name.\n",
    "  Returns: \n",
    "    A dtuple of (inputs, outputs).\n",
    "  \"\"\"\n",
    "  inputsList = [inputs.get(key) for key in FEATURES]\n",
    "  stacked = tf.stack(inputsList, axis=0)\n",
    "  # Convert from CHW to HWC\n",
    "  stacked = tf.transpose(stacked, [1, 2, 0])\n",
    "  return stacked[:,:,:len(BANDS)], stacked[:,:,len(BANDS):]\n",
    "\n",
    "\n",
    "def get_dataset(pattern):\n",
    "  \"\"\"Function to read, parse and format to tuple a set of input tfrecord files.\n",
    "  Get all the files matching the pattern, parse and convert to tuple.\n",
    "  Args:\n",
    "    pattern: A file pattern to match in a Cloud Storage bucket.\n",
    "  Returns: \n",
    "    A tf.data.Dataset\n",
    "  \"\"\"\n",
    "  # glob = tf.gfile.Glob(pattern) for tendorflow 1.x\n",
    "  glob = tf.io.gfile.glob(pattern) # for tendorflow 2.x\n",
    "  dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
    "  dataset = dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
    "  dataset = dataset.map(to_tuple, num_parallel_calls=5)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d1b7b-69d9-4d94-a063-f17122caf14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_dataset():\n",
    "    version_samples_acc = \"2\"\n",
    "    glob='/home/mluize/modelos/storage/mb7-unet-apicum/train/samples_v'+version_samples_acc+'/'+ TRAINING_BASE + '*'\n",
    "    dataset = get_dataset(glob)\n",
    "    dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "    return dataset\n",
    "training = get_training_dataset()\n",
    "print(training.take(1))\n",
    "\n",
    "def get_eval_dataset():\n",
    "    version_samples_acc = \"2\"\n",
    "    glob = '/home/mluize/modelos/storage/mb7-unet-apicum/eval/samples_v'+version_samples_acc+ '/'+ EVAL_BASE + '*'\n",
    "    dataset = get_dataset(glob)\n",
    "    dataset = dataset.batch(3).repeat()\n",
    "    return dataset\n",
    "evaluation = get_eval_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3c5e57-38f2-4a11-8f97-f189c0a37d6f",
   "metadata": {},
   "source": [
    "# U shaped CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81c72ac-b412-44a1-8ee4-88b998712c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "def conv_block(input_tensor, num_filters):\n",
    "    encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
    "    encoder = layers.BatchNormalization()(encoder)\n",
    "    encoder = layers.Activation('relu')(encoder)\n",
    "    encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
    "    encoder = layers.BatchNormalization()(encoder)\n",
    "    encoder = layers.Activation('relu')(encoder)\n",
    "    return encoder\n",
    "\n",
    "def encoder_block(input_tensor, num_filters):\n",
    "    encoder = conv_block(input_tensor, num_filters)\n",
    "    encoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
    "    return encoder_pool, encoder\n",
    "\n",
    "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
    "    decoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
    "    decoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
    "    decoder = layers.BatchNormalization()(decoder)\n",
    "    decoder = layers.Activation('relu')(decoder)\n",
    "    decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "    decoder = layers.BatchNormalization()(decoder)\n",
    "    decoder = layers.Activation('relu')(decoder)\n",
    "    decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "    decoder = layers.BatchNormalization()(decoder)\n",
    "    decoder = layers.Activation('relu')(decoder)\n",
    "    return decoder\n",
    "\n",
    "def get_model():\n",
    "    inputs = layers.Input(shape=[None, None, len(BANDS)]) # 256 (shape=[256, 256, len(BANDS)\n",
    "    encoder0_pool, encoder0 = encoder_block(inputs, 64) # 128\n",
    "    encoder1_pool, encoder1 = encoder_block(encoder0_pool, 128) # 64\n",
    "    encoder2_pool, encoder2 = encoder_block(encoder1_pool, 256) # 32\n",
    "    encoder3_pool, encoder3 = encoder_block(encoder2_pool, 512) # 16\n",
    "    center = conv_block(encoder3_pool, 1024) # 8 center\n",
    "    decoder4 = decoder_block(center, encoder3, 512) # 16\n",
    "    decoder3 = decoder_block(decoder4, encoder2, 256) # 32\n",
    "    decoder2 = decoder_block(decoder3, encoder1, 128) # 64\n",
    "    decoder1 = decoder_block(decoder2, encoder0, 64) # 128\n",
    "    dropout = layers.Dropout(DROPOUT, name=\"dropout\", noise_shape=None, seed=None)(decoder1)\n",
    "    outputs = layers.Conv2D(1, (1, 1),  activation=tf.nn.sigmoid, padding='same', \\\n",
    "                            kernel_initializer=tf.keras.initializers.GlorotNormal())(dropout) #tensorflow 2.x\n",
    "    \n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    optimizer = tf.keras.optimizers.Nadam( 0.000005, name='optimizer')\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss=losses.get(LOSS),\n",
    "        metrics=[metrics.get(metric) for metric in METRICS]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588b86b6-b4ca-4122-9e03-a447ce30b5e5",
   "metadata": {},
   "source": [
    "# Model Selection/Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984a7d0c-b216-4f33-9d92-4700e8e17e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "m = get_model() # UNET\n",
    "UNET_VERSION = '2'\n",
    "VERSION = str(VERSION)\n",
    "EPOCH = 0\n",
    "CHECK_MODEL_DIR = '/home/mluize/storage4/modelos/mb7-unet-apicum/checkpoint/v'+str(UNET_VERSION)+'/cp-0'+str(EPOCH)+'.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f302b-576a-4d1e-8cbc-d929f02ffa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def previewClass(epoch,log):\n",
    "    counter = 0\n",
    "    for batch in evaluation.shuffle(1000).take(3):\n",
    "        pureImage = batch[0]\n",
    "        supervised = batch[1]\n",
    "        stacked = tf.transpose(pureImage[0],[0,1,2]).numpy()\n",
    "        stackedS=tf.transpose(supervised[0],[0,1,2]).numpy()\n",
    "        test_pred_raw = m.predict(pureImage)\n",
    "        test_pred_raw = tf.transpose(test_pred_raw[0],[0,1,2]).numpy()\n",
    "        fig = plt.figure(figsize=[12,4])\n",
    "        # show original image\n",
    "        fig.add_subplot(131)\n",
    "        plt.imshow(stacked[:,:,0:3].astype(np.uint8), \\\n",
    "                   interpolation='nearest', vmin=0, vmax=255)\n",
    "        fig.add_subplot(132)\n",
    "        plt.imshow(stackedS[:,:,0], \\\n",
    "                   interpolation='nearest',cmap=\"gray\")\n",
    "        fig.add_subplot(133)\n",
    "        plt.imshow(test_pred_raw[:,:,0], \\\n",
    "                   interpolation='nearest',cmap=\"gray\")\n",
    "        plt.show()\n",
    "        counter = counter+1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0ffa57-4d31-4445-b086-c771c620bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.style.use(\"ggplot\")\n",
    "checkpoint_path = CHECK_MODEL_DIR+\"/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir  = os.path.dirname(checkpoint_path)\n",
    "\n",
    "log_dir = '/home/mluize/storage4/modelos/mb7-unet-apicum/output/v'+VERSION\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir+'/log_model',write_images=True)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,verbose=1, save_weights_only=True, period=2)\n",
    "img_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=previewClass)\n",
    "\n",
    "result = m.fit(x=training,\n",
    "  epochs=80,\n",
    "  initial_epoch=0, \n",
    "  steps_per_epoch=2000,\n",
    "  verbose=1,\n",
    "  shuffle=True,\n",
    "  validation_data=evaluation,\n",
    "  validation_steps=10000,\n",
    "  callbacks = [cp_callback,tensorboard,img_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ee17e7-3786-4535-b6e5-01c7829b9d1b",
   "metadata": {},
   "source": [
    "# Modaic Exportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b350b49-6062-4ac5-8f2b-c948e54b7803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doExport(out_image_base,index_in, kernel_buffer, roi):\n",
    "  \"\"\"Run the image export task.  Block until complete.\n",
    "  \"\"\"\n",
    "  index = index_in\n",
    "  image = ee.Image('users/MariaLuizeSolvedCurso/Masters/mosaic_'+str(index))\n",
    "  out_image_base2 = out_image_base+'_'+str(index_in)\n",
    "  filesList= !ls '/mnt/storage/allPatch/'{out_image_base2}'*'\n",
    "  print(filesList)\n",
    "  exportFilesList = [s for s in filesList if out_image_base in s]\n",
    "  if(len(exportFilesList) > 1):\n",
    "    print('Image Already Exported')\n",
    "    return None\n",
    "  print(\"Exporting..\") \n",
    "  print(BANDS)\n",
    "  task = ee.batch.Export.image.toDrive(\n",
    "    image = image.select(BANDS).toFloat(), \n",
    "    description = out_image_base+'_'+str(index), \n",
    "    folder = 'mosaics_unet_'+str(index), \n",
    "    fileNamePrefix = out_image_base+'_'+str(index), \n",
    "    region = roi, \n",
    "    scale = 30, \n",
    "    fileFormat = 'TFRecord', \n",
    "    maxPixels = 1e13,\n",
    "    formatOptions = { \n",
    "      'patchDimensions': KERNEL_SHAPE,\n",
    "      'kernelSize': kernel_buffer,\n",
    "      'compressed': True,\n",
    "      'maxFileSize': 104857600\n",
    "    }\n",
    "  )\n",
    "  task.start()\n",
    "\n",
    "  print('Running image export to Cloud Storage...')\n",
    "  import time\n",
    "  time.sleep(1)\n",
    "  # Error condition\n",
    "  if task.status()['state'] != 'COMPLETED':\n",
    "    print('Error with image export.')\n",
    "  else:\n",
    "    print('Image export completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7674c75-f8af-48b0-b775-6395e52c1bd7",
   "metadata": {},
   "source": [
    "# Mosaic Patches Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dcdf16-0f2a-47ac-9e12-a4f555d27750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doPrediction(out_image_base,index_in,region_id, user_folder, kernel_buffer, region):\n",
    "  \"\"\"Perform inference on exported imagery, upload to Earth Engine.\n",
    "  \"\"\"\n",
    "  out_image_base = out_image_base+'_'+str(index_in)\n",
    "  filesList = glob.glob(\"/home/mluize/mosaics_landsat/\"+str(index_in)+\"/\"+out_image_base+\"*\")\n",
    "\n",
    "  print(out_image_base)\n",
    "  rasterFolder = OUTPUT_PATH  + '/classifications_tiff/'+str(index_in)\n",
    "  rasterURILZW = rasterFolder + '/outimage_'+VERSION+'_'+str(region_id)+'_'+str(index_in)+'_lzw.tif'\n",
    "\n",
    "  if os.path.exists(rasterURILZW):\n",
    "        print('Arquivo ja predito \\n\\n')\n",
    "        return None\n",
    "    \n",
    "  if(len(filesList) == 0):\n",
    "    print('Sem arquivos')\n",
    "    !echo 'ERRO! (Sem arquivos) grid={y} - {region_id}' >> log.log\n",
    "    return None\n",
    "  exportFilesList = [s for s in filesList if out_image_base in s]    \n",
    "    \n",
    "\n",
    "  # Get the list of image files and the JSON mixer file.\n",
    "  imageFilesList = []\n",
    "  jsonFile = None\n",
    "  for f in exportFilesList:\n",
    "    if f.endswith('.tfrecord.gz'):\n",
    "      imageFilesList.append(f)\n",
    "    elif f.endswith('.json'):\n",
    "      jsonFile = f\n",
    "\n",
    "  # Make sure the files are in the right order.\n",
    "  imageFilesList.sort()\n",
    "  \n",
    "  predictioned_file =  !gsutil ls 'gs://'{BUCKET_patch}'/'{FOLDER_classification}'/'{VERSION}'/'{out_image_base}'.TFRecord'\n",
    "  out_image_asset = user_folder + '/' + out_image_base\n",
    "  out_image_file = 'gs://' + BUCKET_patch + '/' + FOLDER_classification + '/'+VERSION+'/' + out_image_base + '.TFRecord'\n",
    "  \n",
    "  # Load the contents of the mixer file to a JSON object.\n",
    "  jsonText = open(jsonFile)\n",
    "  # Get a single string w/ newlines from the IPython.utils.text.SList\n",
    "  mixer = json.load(jsonText)\n",
    "  \n",
    "  patches = mixer['totalPatches']\n",
    "  cols = int(mixer[\"patchesPerRow\"])\n",
    "  rows = int(mixer[\"totalPatches\"]/cols)\n",
    "  \n",
    "  # Get set up for prediction.\n",
    "  x_buffer = int(kernel_buffer[0] / 2)\n",
    "  y_buffer = int(kernel_buffer[1] / 2)\n",
    "  \n",
    "  buffered_shape = [\n",
    "      KERNEL_SHAPE[0] + kernel_buffer[0],\n",
    "      KERNEL_SHAPE[1] + kernel_buffer[1]]\n",
    "\n",
    "  imageColumns = [\n",
    "    tf.io.FixedLenFeature(shape=buffered_shape, dtype=tf.float32) #Tensorflow 2.x\n",
    "      for k in BANDS\n",
    "  ]  \n",
    "    \n",
    "  imageFeaturesDict = dict(zip(BANDS, imageColumns))\n",
    "  def parse_image(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, imageFeaturesDict) #Tensorflow 2.x\n",
    "\n",
    "  def toTupleImage(inputs):\n",
    "    inputsList = [inputs[key] for key in BANDS] #BANDS\n",
    "    stacked = tf.stack(inputsList, axis=0)\n",
    "    stacked = tf.transpose(stacked, [1, 2, 0])\n",
    "    return stacked\n",
    "  \n",
    "  # Create a dataset from the TFRecord file(s) in Cloud Storage.\n",
    "  imageDataset = tf.data.TFRecordDataset(imageFilesList, compression_type='GZIP')\n",
    "  imageDataset = imageDataset.map(parse_image, num_parallel_calls=4)\n",
    "  imageDataset = imageDataset.map(toTupleImage).batch(1)\n",
    "    \n",
    "  # Perform inference.\n",
    "  predictions = m.predict(imageDataset, steps=patches, verbose=2)\n",
    "  patchesPerRow  = mixer['patchesPerRow']\n",
    "  TotalPatches   = mixer['totalPatches']\n",
    "  patchDimension = mixer['patchDimensions']\n",
    "\n",
    "  #Manipulating Prediction Numpy Array OUTPUT\n",
    "  counter       = 1\n",
    "  rowCounter    = 1\n",
    "  globalCounter = 0\n",
    "  finalArray    = numpy.array([])\n",
    "\n",
    "  rowArray = numpy.array([])\n",
    "  for raw_record in predictions:\n",
    "      raw_record = numpy.squeeze(raw_record) #Exclude Bands\n",
    "      rows,cols = raw_record.shape\n",
    "      raw_record = raw_record[128:384,128:384]\n",
    "      if rowCounter == 1:\n",
    "          finalArray = rowArray\n",
    "      if counter <= patchesPerRow:\n",
    "          if counter == 1:\n",
    "              rowArray = raw_record\n",
    "          else:\n",
    "              rowArray = numpy.concatenate((rowArray,raw_record), axis = 1)\n",
    "          counter = counter+1\n",
    "      else:\n",
    "          counter = 2\n",
    "          rowCounter = rowCounter+1\n",
    "          if numpy.array_equal(finalArray,rowArray):\n",
    "              finalArray = rowArray\n",
    "          else:\n",
    "              finalArray = numpy.concatenate((finalArray,rowArray),axis=0)\n",
    "          rowArray = raw_record\n",
    "      globalCounter = globalCounter+1\n",
    "  finalArray = numpy.concatenate((finalArray,rowArray),axis=0)\n",
    "  show(Image.fromarray(finalArray))\n",
    "  rows,cols = finalArray.shape\n",
    "\n",
    "  driver = gdal.GetDriverByName(\"GTiff\")\n",
    "\n",
    "  finalArray2  = numpy.array([finalArray])\n",
    "  rasterFolder = OUTPUT_PATH  + '/classifications_tiff/'+str(index_in)\n",
    "\n",
    "  if not os.path.exists(rasterFolder):\n",
    "    print('lets make the directory')\n",
    "    os.makedirs(rasterFolder)\n",
    "  \n",
    "  rasterURI    = rasterFolder + '/UNET_v'+VERSION+'_grid_'+str(region_id)+'_year_'+str(index_in)+'.tif'\n",
    "  rasterURILZW = rasterFolder + '/outimage_'+VERSION+'_'+str(region_id)+'_'+str(index_in)+'_lzw.tif'\n",
    " \n",
    "  with rasterio.open(rasterURI,'w',\n",
    "          driver=\"GTiff\",\n",
    "          height=rows,\n",
    "          width=cols,\n",
    "          count=1,\n",
    "          dtype=\"float32\",\n",
    "          crs=mixer[\"projection\"][\"crs\"],\n",
    "          transform=mixer[\"projection\"][\"affine\"][\"doubleMatrix\"],\n",
    "          nodata=\"nan\") as dataset:\n",
    "              dataset.write(finalArray2)\n",
    "  !gdal_translate -of GTiff -co \"COMPRESS=LZW\" -co \"PREDICTOR=2\" -co \"TILED=YES\" {rasterURI} {rasterURILZW}\n",
    "  !rm {rasterURI}\n",
    "  out_image_asset = user_folder + '/' + out_image_base\n",
    "    \n",
    "  print('Writing predictions...')\n",
    "  out_image_file  = rasterFolder+'/' + out_image_base + '.TFRecord'\n",
    "  out_image_mixer = rasterFolder+'/'+ out_image_base + '.json'\n",
    "  #------------TFRECORD WRITE ------------\n",
    "  writer = tf.io.TFRecordWriter(out_image_file)\n",
    "  patches = 0\n",
    "  for predictionPatch in predictions:\n",
    "    predictionPatch = predictionPatch[\n",
    "        x_buffer:x_buffer+KERNEL_SIZE, y_buffer:y_buffer+KERNEL_SIZE]\n",
    "\n",
    "    # Create an example.\n",
    "    example = tf.train.Example(\n",
    "      features=tf.train.Features(\n",
    "        feature={\n",
    "          'classification': tf.train.Feature(\n",
    "              float_list=tf.train.FloatList(\n",
    "                  value=predictionPatch.flatten()))\n",
    "        }\n",
    "      )\n",
    "    )\n",
    "    # Write the example.\n",
    "    writer.write(example.SerializeToString())\n",
    "    patches += 1\n",
    "\n",
    "  writer.close()\n",
    "  !cp {jsonFile} {out_image_mixer}\n",
    "\n",
    "\n",
    "#   UPLOAD TFRecord TO BUCKET, THEN TO GEE\n",
    "  !gsutil -o GSUtil:parallel_composite_upload_threshold=150M cp  {out_image_file} {gcs_path}\n",
    "  !gsutil cp {jsonFile} {gcs_json}\n",
    "  print('gsutil cp '+jsonFile+' '+gcs_json)\n",
    "  \n",
    "  # Start the upload.\n",
    "  print('earthengine upload image  --asset_id='+out_image_asset+''+gcs_path+' '+gcs_json+')\\n')  \n",
    "  print('out_image_asset: '+out_image_asset+'\\n')\n",
    "  print('gcs_path: '+gcs_path+'\\n')\n",
    "  print('gcs_json: '+gcs_json+'\\n')\n",
    "  !earthengine upload image   --asset_id={out_image_asset} {gcs_path} {gcs_json}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc898285-a645-4c76-9872-41288b4d25d8",
   "metadata": {},
   "source": [
    "# Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0155b779-a0b8-4278-a8c9-f08b8649f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygeoj\n",
    "kernel_buffer = [256, 256]\n",
    "image_base_name = 'allPatch_UNET_grid_'\n",
    "grid = pygeoj.load('/home/mluize/storage4/modelos/GRID/GRID-ALLCALSSES-COL8-19052023.geojson')\n",
    "print(\"Total Features on GRID\")\n",
    "print(len(grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b804e38-3f48-4657-aaf0-4a4872a170a3",
   "metadata": {},
   "source": [
    "# Mosaic Exportation Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeb8d98-e373-4e49-bdf5-a08ff06cfbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the export.\n",
    "for region in grid:\n",
    "    region_id = int(region.properties['id'])\n",
    "    if int(region_id) > 0 and region.properties['apicum'] == 1 and (region_id == 1975):\n",
    "      print('Region:')\n",
    "      print(region.geometry.coordinates)\n",
    "      for y in range(2020, 2021):\n",
    "          doExport(image_base_name+str(region_id)+str('_' + MOSAIC_VERSION),y, kernel_buffer, region.geometry.coordinates[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6a692e-7cfb-4144-9151-8e844a2452a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prediction Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296d9509-9699-4ffe-8ed8-2ee492c8a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "image_base_name = 'allPatch_UNET_grid_'\n",
    "MOSAIC_VERSION  = '1'\n",
    "print(MOSAIC_VERSION)\n",
    "for y in  range(2020, 2021):\n",
    "    start = time.time()\n",
    "    print('starting...')\n",
    "    !echo 'year={y}' >> log.log\n",
    "    processed_grids = []\n",
    "    for region in grid:\n",
    "        region_id = region.properties['id']\n",
    "        region_id = int(region_id)\n",
    "        if region.properties['apicum'] == 1 and not (region_id in processed_grids):\n",
    "            processed_grids.append(region_id)\n",
    "            print(f\"region: {region_id}, year: {y}\")\n",
    "            user_folder = 'projects/solvedltda/assets/MB7_Apicum/v2/unet_prediction'\n",
    "            print('Predicting')\n",
    "            doPrediction(image_base_name+str(region_id)+str('_' + MOSAIC_VERSION),y,region_id, user_folder, kernel_buffer, region.geometry.coordinates)\n",
    "            print('Finish')\n",
    "            !echo 'grid={y} -{region_id}' >> log.log\n",
    "    end = time.time()\n",
    "    print('Prediction Time per year = '+str(end - start))\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bd49e8-137a-4903-91af-5c13dfba89e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -o GSUtil:parallel_composite_upload_threshold=15M -m cp -n /home/mluize/storage4/modelos/mb7-unet-apicum/output/v2/classifications_tiff/2020/*.tif gs://mineracao_mb8/classification_mb8_apicum/\n",
    "!ls -1 /home/mluize/storage4/modelos/mb7-unet-apicum/output/v2/classifications_tiff/2020/*.tif > lista\n",
    "!sh geeUpload.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Geral)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
